{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab49146b-49b0-4250-936f-e2461eafb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "files = ['goemotions_1.csv', 'goemotions_2.csv', 'goemotions_3.csv']\n",
    "\n",
    "dfs = [pd.read_csv(file) for file in files]\n",
    "\n",
    "df_text = pd.concat(dfs, ignore_index=True)\n",
    "df_words = pd.read_csv('emotion_words.csv')\n",
    "\n",
    "emotion_columns = df_text.columns[df_text.columns.get_loc(\"admiration\"):].tolist()\n",
    "\n",
    "df_text[\"dominant_emotion\"] = df_text[emotion_columns].idxmax(axis=1)\n",
    "\n",
    "df_oryginal = df_text[['text', 'dominant_emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832984bc-60a1-4dee-afae-8ff24fd6195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dominant_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldnâ€™t be a grouping category I...</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>Everyone likes [NAME].</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>Well when youâ€™ve imported about a gazillion of...</td>\n",
       "      <td>caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>That looks amazing</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>The FDA has plenty to criticize. But like here...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text dominant_emotion\n",
       "0                                         That game hurt.          sadness\n",
       "1        >sexuality shouldnâ€™t be a grouping category I...       admiration\n",
       "2          You do right, if you don't care then fuck 'em!          neutral\n",
       "3                                      Man I love reddit.             love\n",
       "4       [NAME] was nowhere near them, he was by the Fa...          neutral\n",
       "...                                                   ...              ...\n",
       "211220                             Everyone likes [NAME].             love\n",
       "211221  Well when youâ€™ve imported about a gazillion of...           caring\n",
       "211222                                 That looks amazing       admiration\n",
       "211223  The FDA has plenty to criticize. But like here...            anger\n",
       "211224  Desktop link: ^^/r/HelperBot_ ^^Downvote ^^to ...       admiration\n",
       "\n",
       "[211225 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oryginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec45656-b38c-4e43-9c58-7dc95b2b35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Ziolek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ziolek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Ziolek\\AppData\\Local\\Temp\\ipykernel_13040\\1683528834.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_oryginal['text'] = df_oryginal['text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df_oryginal['text'] = df_oryginal['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2197e40-5708-4e61-847c-1faa3d3876ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dominant_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>game hurt</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexuality grouping category make different oth...</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>right care fuck</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man love reddit</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name nowhere near falcon</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211220</th>\n",
       "      <td>everyone like name</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211221</th>\n",
       "      <td>well imported gazillion country get serious</td>\n",
       "      <td>caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211222</th>\n",
       "      <td>look amazing</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211223</th>\n",
       "      <td>fda plenty criticize like usually criticized h...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211224</th>\n",
       "      <td>desktop link</td>\n",
       "      <td>admiration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text dominant_emotion\n",
       "0                                               game hurt          sadness\n",
       "1       sexuality grouping category make different oth...       admiration\n",
       "2                                         right care fuck          neutral\n",
       "3                                         man love reddit             love\n",
       "4                                name nowhere near falcon          neutral\n",
       "...                                                   ...              ...\n",
       "211220                                 everyone like name             love\n",
       "211221        well imported gazillion country get serious           caring\n",
       "211222                                       look amazing       admiration\n",
       "211223  fda plenty criticize like usually criticized h...            anger\n",
       "211224                                       desktop link       admiration\n",
       "\n",
       "[211225 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oryginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca0d5fd-ef37-424c-8ba4-8a443a77f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_oryginal.copy()\n",
    "df = df[:100] # tylko 100 rekordÃ³w dla szybkoÅ›ci trenowania, oversampling i tak sztucznie zwiÄ™kszy zbiÃ³r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6c716f-54f8-4797-b2e1-443d0395722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dominant_emotion\n",
       "neutral           21\n",
       "admiration        11\n",
       "disapproval        7\n",
       "annoyance          6\n",
       "confusion          6\n",
       "curiosity          6\n",
       "gratitude          5\n",
       "caring             4\n",
       "joy                4\n",
       "disappointment     4\n",
       "amusement          4\n",
       "love               4\n",
       "anger              3\n",
       "remorse            3\n",
       "approval           2\n",
       "embarrassment      2\n",
       "optimism           2\n",
       "surprise           1\n",
       "sadness            1\n",
       "disgust            1\n",
       "excitement         1\n",
       "realization        1\n",
       "grief              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dominant_emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7a8d96-9e6a-43c2-98be-54a82acdd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='not majority', random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(df[['text']], df['dominant_emotion'])\n",
    "df_balanced = pd.DataFrame({'text': X_resampled.squeeze(), 'dominant_emotion': y_resampled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9475cbda-1c66-47a3-bf0c-0b81a8e2cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dominant_emotion\n",
       "sadness           21\n",
       "curiosity         21\n",
       "anger             21\n",
       "surprise          21\n",
       "embarrassment     21\n",
       "approval          21\n",
       "joy               21\n",
       "remorse           21\n",
       "disgust           21\n",
       "caring            21\n",
       "excitement        21\n",
       "optimism          21\n",
       "admiration        21\n",
       "confusion         21\n",
       "annoyance         21\n",
       "realization       21\n",
       "disappointment    21\n",
       "amusement         21\n",
       "disapproval       21\n",
       "gratitude         21\n",
       "love              21\n",
       "neutral           21\n",
       "grief             21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['dominant_emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af70da09-2f2a-424f-be26-02bdd12668c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ziolek\\Desktop\\python\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ziolek\\Desktop\\python\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Ziolek\\Desktop\\python\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 03:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.601949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.112718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.938859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.938858985900879, 'eval_runtime': 2.9562, 'eval_samples_per_second': 32.813, 'eval_steps_per_second': 2.368, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = df_balanced.copy()\n",
    "le = LabelEncoder()\n",
    "df_train['label'] = le.fit_transform(df_balanced['dominant_emotion'])\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels, indices_train, indices_test = train_test_split(\n",
    "    df_train['text'], df_train['label'], df_train['text'].index, test_size=0.2, random_state=42\n",
    ")\n",
    "train_dataset = EmotionDataset(train_texts.tolist(), train_labels.tolist())\n",
    "test_dataset = EmotionDataset(test_texts.tolist(), test_labels.tolist())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(le.classes_))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea35954e-371f-44b6-b236-0f48060ba6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ modelu: 0.8041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = predictions.predictions.argmax(axis=1)\n",
    "y_true = test_labels.tolist()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ modelu: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e371590-ca31-4598-9459-2a153d8916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = labels.set_index('label')['dominant_emotion'].to_dict()\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'actual' : y_true,\n",
    "    'predict': y_pred\n",
    "})\n",
    "\n",
    "results_df['actual_emotion'] = results_df['actual'].map(labels_dict)\n",
    "results_df['predict_emotion'] = results_df['predict'].map(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2437491-2db8-4e49-9e30-7d50939e317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "      <th>actual_emotion</th>\n",
       "      <th>predict_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>realization</td>\n",
       "      <td>realization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>surprise</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>caring</td>\n",
       "      <td>caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>excitement</td>\n",
       "      <td>excitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>curiosity</td>\n",
       "      <td>curiosity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>optimism</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>gratitude</td>\n",
       "      <td>gratitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>grief</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>amusement</td>\n",
       "      <td>amusement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual  predict actual_emotion predict_emotion\n",
       "0       19       19    realization     realization\n",
       "1       22       22       surprise        surprise\n",
       "2        5        5         caring          caring\n",
       "3       21       21        sadness         sadness\n",
       "4       12       12     excitement      excitement\n",
       "..     ...      ...            ...             ...\n",
       "92       7        7      curiosity       curiosity\n",
       "93      18       18       optimism        optimism\n",
       "94      13       13      gratitude       gratitude\n",
       "95      14       14          grief           grief\n",
       "96       1        1      amusement       amusement\n",
       "\n",
       "[97 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32783fb-8701-46c3-b4e5-ceb894c04016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
